{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chess\n",
    "import chess.pgn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from classes import SimpleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ''\n",
    "output_file = ''\n",
    "\n",
    "# Define piece types and colors\n",
    "PIECE_TYPES = [None, chess.PAWN, chess.KNIGHT, chess.BISHOP, chess.ROOK, chess.QUEEN, chess.KING]\n",
    "PIECE_COLORS = [chess.WHITE, chess.BLACK]\n",
    "\n",
    "def encode_board(board):\n",
    "    encoded = []\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        square_encoded = [0] * 13  # 12 for pieces + 1 for empty square\n",
    "        \n",
    "        if piece:\n",
    "            index = PIECE_TYPES.index(piece.piece_type) + (piece.color * 6) - 1\n",
    "            square_encoded[index] = 1\n",
    "        else:\n",
    "            square_encoded[-1] = 1\n",
    "            \n",
    "        encoded.extend(square_encoded)\n",
    "    return encoded\n",
    "\n",
    "def encode_move(move):\n",
    "    encoded = [0] * 4096 #64 * 64 possible moves\n",
    "    index = move.from_square * 64 + move.to_square\n",
    "    encoded[index] = 1\n",
    "    return encoded\n",
    "\n",
    "def process_pgn_to_tensors(pgn_file_path, output_file_path):\n",
    "    board_states = []\n",
    "    moves = []\n",
    "    i = 0\n",
    "    with open(pgn_file_path) as pgn:\n",
    "        while True:\n",
    "            i += 1\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Processed {i} games\")\n",
    "            if i >= 1000:\n",
    "                break #end early TODO: remove\n",
    "            game = chess.pgn.read_game(pgn)\n",
    "            if game is None:\n",
    "                break  # End of PGN file\n",
    "            board = game.board()\n",
    "            for move in game.mainline_moves():\n",
    "                board_states.append(encode_board(board))\n",
    "                moves.append(encode_move(move))\n",
    "                board.push(move)\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    board_states_tensor = torch.tensor(board_states, dtype=torch.float32)\n",
    "    moves_tensor = torch.tensor(moves, dtype=torch.float32)\n",
    "    \n",
    "    # Save tensors\n",
    "    torch.save((board_states_tensor, moves_tensor), output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_pgn_to_tensors(file_path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNet, self).__init__()\n",
    "\n",
    "        self.input_size = 832  # 64 squares * 13 possible states per square\n",
    "        self.hidden_sizes = [1024, 1024, 2048, 2048, 4096] \n",
    "        self.output_size = 4096  # 64 starting squares * 64 destination squares\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        self.layers.append(nn.Linear(self.input_size, self.hidden_sizes[0]))\n",
    "        \n",
    "        for i in range(len(self.hidden_sizes) - 1):\n",
    "            self.layers.append(nn.Linear(self.hidden_sizes[i], self.hidden_sizes[i+1]))\n",
    "        \n",
    "        self.layers.append(nn.Linear(self.hidden_sizes[-1], self.output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        x = self.layers[-1](x)  \n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8\n",
    "x , y = torch.load(\"/Users/mikil/Desktop/SideProjects/MiscML/Chess_Classification/Chess Dataset/data.pt\")\n",
    "x_train = x[:int(train_split*len(x))]\n",
    "y_train = y[:int(train_split*len(y))]\n",
    "x_test = x[int(train_split*len(x)):]\n",
    "y_test = y[int(train_split*len(y)):]\n",
    "\n",
    "train_dataset = SimpleDataset(x_train, y_train)\n",
    "test_dataset = SimpleDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "model = ChessNet()\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "\n",
    "loss_funtion  = nn.CrossEntropyLoss()\n",
    "\n",
    "data_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "data_test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_accuracy():\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(data_test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_funtion(outputs, targets)\n",
    "            total_loss += loss.item() * inputs.size(0)  # Multiply by batch size to get total loss for this batch\n",
    "            total_samples += inputs.size(0)\n",
    "    \n",
    "    average_loss = total_loss / total_samples\n",
    "    return average_loss\n",
    "\n",
    "compute_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0 \n",
    "    progress_bar = tqdm(data_train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for inputs, targets in progress_bar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_funtion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        average_loss = epoch_loss / (progress_bar.n + 1)\n",
    "        progress_bar.set_description(f\"Epoch {epoch + 1}/{epochs}, Loss: {average_loss:.4f}\")\n",
    "\n",
    "    # Validate the model\n",
    "    val_loss, val_accuracy = compute_test_accuracy()\n",
    "    progress_bar.set_postfix(val_loss=val_loss, val_acc=val_accuracy)\n",
    "\n",
    "    #update the learning rate scheduler\n",
    "    scheduler.step(average_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainpython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
